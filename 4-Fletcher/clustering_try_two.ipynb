{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_data import *\n",
    "\n",
    "titles, transcripts = import_from_mongo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ryanmurray/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ryanmurray/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_stem(text):\n",
    "    #First tokenizes by sentence, then by word, so that punctuation is caught as its own token\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    for token in tokens:\n",
    "        #Filter out tokens not containing letters\n",
    "        if re.search('[a-zA-Z]' ,token):\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_only(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "totalvocab_stemmed = []\n",
    "totalvocab_tokenized = []\n",
    "for i in transcripts:\n",
    "    allwords_stemmed = tokenize_and_stem(i) #for each item in 'synopses', tokenize/stem\n",
    "    totalvocab_stemmed.extend(allwords_stemmed) #extend the 'totalvocab_stemmed' list\n",
    "    \n",
    "    allwords_tokenized = tokenize_only(i)\n",
    "    totalvocab_tokenized.extend(allwords_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_frame = pd.DataFrame({'words': totalvocab_tokenized}, index = totalvocab_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 10223115 items in vocab_frame\n"
     ]
    }
   ],
   "source": [
    "print ('there are ' + str(vocab_frame.shape[0]) + ' items in vocab_frame')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>You</th>\n",
       "      <td>you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'ve</th>\n",
       "      <td>'ve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heard</th>\n",
       "      <td>heard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>your</th>\n",
       "      <td>your</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       words\n",
       "You      you\n",
       "'ve      've\n",
       "heard  heard\n",
       "of        of\n",
       "your    your"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 46s, sys: 1.12 s, total: 1min 47s\n",
      "Wall time: 1min 47s\n",
      "(5858, 260)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#define vectorizer parameters\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.6, max_features=200000,\n",
    "                                 min_df=0.2, stop_words='english',\n",
    "                                 use_idf=True, tokenizer=tokenize_and_stem, ngram_range=(1,3))\n",
    "\n",
    "%time tfidf_matrix = tfidf_vectorizer.fit_transform(transcripts) #fit the vectorizer to synopses\n",
    "\n",
    "print(tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5858x260 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 477719 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "dist = 1 - cosine_similarity(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 20s, sys: 16 ms, total: 1min 20s\n",
      "Wall time: 1min 20s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "num_clusters = 10\n",
    "\n",
    "km = KMeans(n_clusters=num_clusters)\n",
    "\n",
    "%time km.fit(tfidf_matrix)\n",
    "\n",
    "clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ted = { 'title': titles,  'transcript': transcripts, 'cluster': clusters}\n",
    "\n",
    "frame = pd.DataFrame(ted, columns = ['title', 'cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10 myths about psychology debunked Ben Ambridge</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10 things you didn't know about orgasm Mary Roach</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10 top time saving tech tips David Pogue</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10 ways to have a better conversation Celeste ...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 sustainable design ideas from nature Janine...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  cluster\n",
       "0    10 myths about psychology debunked Ben Ambridge        4\n",
       "1  10 things you didn't know about orgasm Mary Roach        6\n",
       "2           10 top time saving tech tips David Pogue        2\n",
       "3  10 ways to have a better conversation Celeste ...        6\n",
       "4  12 sustainable design ideas from nature Janine...        0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    1767\n",
       "6    1293\n",
       "1    1187\n",
       "8     416\n",
       "2     245\n",
       "4     221\n",
       "7     206\n",
       "0     198\n",
       "3     191\n",
       "9     134\n",
       "Name: cluster, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "\n",
      "Cluster 0 words: b'water', b'use', b'food', b'called', b'place', b'got',\n",
      "\n",
      "Cluster 1 words: b'questions', b'word', b'words', b'use', b'called', b'today',\n",
      "\n",
      "Cluster 2 words: b'light', b'space', b'matter', b'called', b'big', b'ca',\n",
      "\n",
      "Cluster 3 words: b'music', b'applause', b'play', b'yeah', b'hear', b'love',\n",
      "\n",
      "Cluster 4 words: b'women', b'said', b'man', b'day', b'children', b'young',\n",
      "\n",
      "Cluster 5 words: b'technology', b'kind', b'use', b'lot', b'percent', b'human',\n",
      "\n",
      "Cluster 6 words: b'said', b'got', b'did', b'day', b'went', b'love',\n",
      "\n",
      "Cluster 7 words: b'body', b'called', b'human', b'inside', b'use', b'process',\n",
      "\n",
      "Cluster 8 words: b'school', b'children', b'kids', b'said', b'family', b'young',\n",
      "\n",
      "Cluster 9 words: b'food', b'water', b'change', b'body', b'use', b'lot',\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Top terms per cluster:\")\n",
    "print()\n",
    "#sort cluster centers by proximity to centroid\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1] \n",
    "\n",
    "for i in range(num_clusters):\n",
    "    print(\"Cluster %d words:\" % i, end='')\n",
    "    \n",
    "    for ind in order_centroids[i, :6]: #replace 6 with n words per cluster\n",
    "        print(' %s' % vocab_frame.loc[terms[ind].split(' ')].values.tolist()[0][0].encode('utf-8', 'ignore'), end=',')\n",
    "    print() #add whitespace\n",
    "    print() #add whitespace\n",
    "    \n",
    "    '''print(\"Cluster %d titles:\" % i, end='')\n",
    "    for title in frame.loc[i]['title'].values.tolist():\n",
    "        print(' %s,' % title, end='')\n",
    "    print() #add whitespace\n",
    "    print() #add whitespace'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This list of words suggests that I need to decrease the \"max_df\" parameter in the tfidfvectorizer to remove words that are in most of the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "FN0 = 'vocabulary-embedding'\n",
    "\n",
    "with open('data/%s.pkl'%FN0, 'rb') as fp:\n",
    "    embedding, idx2word, word2idx, glove_idx2idx = pickle.load(fp)\n",
    "vocab_size, embedding_size = embedding.shape\n",
    "\n",
    "with open('data/%s.data.pkl'%FN0, 'rb') as fp:\n",
    "    X,Y = pickle.load(fp)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples 5858 5858\n",
      "dimension of embedding space for words 100\n",
      "vocabulary size 40000 the last 30 words can be used as place holders for unknown/oov words\n",
      "total number of different words 203556 203556\n",
      "number of words outside vocabulary which we can substitue using glove similarity 41880\n",
      "number of words that will be regarded as unknonw(unk)/out-of-vocabulary(oov) 121676\n"
     ]
    }
   ],
   "source": [
    "nb_unknown_words = 30\n",
    "print ('number of examples',len(X),len(Y))\n",
    "print ('dimension of embedding space for words',embedding_size)\n",
    "print ('vocabulary size', vocab_size, 'the last %d words can be used as place holders for unknown/oov words'%nb_unknown_words)\n",
    "print ('total number of different words',len(idx2word), len(word2idx))\n",
    "print ('number of words outside vocabulary which we can substitue using glove similarity', len(glove_idx2idx))\n",
    "print ('number of words that will be regarded as unknonw(unk)/out-of-vocabulary(oov)',len(idx2word)-vocab_size-len(glove_idx2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prt(label, x):\n",
    "    print(label+':',)\n",
    "    for w in x:\n",
    "        print(idx2word[w],)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\n",
      "This\n",
      "is\n",
      "Lee\n",
      "Sedol.\n",
      "Lee\n",
      "Sedol\n",
      "is\n",
      "one\n",
      "of\n",
      "the\n",
      "world's\n",
      "greatest\n",
      "Go\n",
      "players,\n",
      "and\n",
      "he's\n",
      "having\n",
      "what\n",
      "my\n",
      "friends\n",
      "in\n",
      "Silicon\n",
      "Valley\n",
      "call\n",
      "a\n",
      "“Holy\n",
      "Cow”\n",
      "moment\n",
      "–\n",
      "a\n",
      "moment\n",
      "where\n",
      "we\n",
      "realize\n",
      "that\n",
      "AI\n",
      "is\n",
      "actually\n",
      "progressing\n",
      "a\n",
      "lot\n",
      "faster\n",
      "than\n",
      "we\n",
      "expected.\n",
      "So\n",
      "humans\n",
      "have\n",
      "lost\n",
      "on\n",
      "the\n",
      "Go\n",
      "board.\n",
      "What\n",
      "about\n",
      "the\n",
      "real\n",
      "world?\n",
      "Well,\n",
      "the\n",
      "real\n",
      "world\n",
      "is\n",
      "much\n",
      "bigger,\n",
      "much\n",
      "more\n",
      "complicated\n",
      "than\n",
      "the\n",
      "Go\n",
      "board.\n",
      "It's\n",
      "a\n",
      "lot\n",
      "less\n",
      "visible,\n",
      "but\n",
      "it's\n",
      "still\n",
      "a\n",
      "decision\n",
      "problem.\n",
      "And\n",
      "if\n",
      "we\n",
      "think\n",
      "about\n",
      "some\n",
      "of\n",
      "the\n",
      "technologies\n",
      "that\n",
      "are\n",
      "coming\n",
      "down\n",
      "the\n",
      "pike\n",
      "…\n",
      "Noriko\n",
      "[Arai]\n",
      "mentioned\n",
      "that\n",
      "reading\n",
      "is\n",
      "not\n",
      "yet\n",
      "happening\n",
      "in\n",
      "machines,\n",
      "at\n",
      "least\n",
      "with\n",
      "understanding.\n",
      "But\n",
      "that\n",
      "will\n",
      "happen,\n",
      "and\n",
      "when\n",
      "that\n",
      "happens,\n",
      "very\n",
      "soon\n",
      "afterwards,\n",
      "machines\n",
      "will\n",
      "have\n",
      "read\n",
      "everything\n",
      "that\n",
      "the\n",
      "human\n",
      "race\n",
      "has\n",
      "ever\n",
      "written.\n",
      "And\n",
      "that\n",
      "will\n",
      "enable\n",
      "machines,\n",
      "along\n",
      "with\n",
      "the\n",
      "ability\n",
      "to\n",
      "look\n",
      "further\n",
      "ahead\n",
      "than\n",
      "humans\n",
      "can,\n",
      "as\n",
      "we've\n",
      "already\n",
      "seen\n",
      "in\n",
      "Go,\n",
      "if\n",
      "they\n",
      "also\n",
      "have\n",
      "access\n",
      "to\n",
      "more\n",
      "information,\n",
      "they'll\n",
      "be\n",
      "able\n",
      "to\n",
      "make\n",
      "better\n",
      "decisions\n",
      "in\n",
      "the\n",
      "real\n",
      "world\n",
      "than\n",
      "we\n",
      "can.\n",
      "So\n",
      "is\n",
      "that\n",
      "a\n",
      "good\n",
      "thing?\n",
      "Well,\n",
      "I\n",
      "hope\n",
      "so.\n",
      "Our\n",
      "entire\n",
      "civilization,\n",
      "everything\n",
      "that\n",
      "we\n",
      "value,\n",
      "is\n",
      "based\n",
      "on\n",
      "our\n",
      "intelligence.\n",
      "And\n",
      "if\n",
      "we\n",
      "had\n",
      "access\n",
      "to\n",
      "a\n",
      "lot\n",
      "more\n",
      "intelligence,\n",
      "then\n",
      "there's\n",
      "really\n",
      "no\n",
      "limit\n",
      "to\n",
      "what\n",
      "the\n",
      "human\n",
      "race\n",
      "can\n",
      "do.\n",
      "And\n",
      "I\n",
      "think\n",
      "this\n",
      "could\n",
      "be,\n",
      "as\n",
      "some\n",
      "people\n",
      "have\n",
      "described\n",
      "it,\n",
      "the\n",
      "biggest\n",
      "event\n",
      "in\n",
      "human\n",
      "history.\n",
      "So\n",
      "why\n",
      "are\n",
      "people\n",
      "saying\n",
      "things\n",
      "like\n",
      "this,\n",
      "that\n",
      "AI\n",
      "might\n",
      "spell\n",
      "the\n",
      "end\n",
      "of\n",
      "the\n",
      "human\n",
      "race?\n",
      "Is\n",
      "this\n",
      "a\n",
      "new\n",
      "thing?\n",
      "Is\n",
      "it\n",
      "just\n",
      "Elon\n",
      "Musk\n",
      "and\n",
      "Bill\n",
      "Gates\n",
      "and\n",
      "Stephen\n",
      "Hawking?\n",
      "Actually,\n",
      "no.\n",
      "This\n",
      "idea\n",
      "has\n",
      "been\n",
      "around\n",
      "for\n",
      "a\n",
      "while.\n",
      "Here's\n",
      "a\n",
      "quotation:\n",
      "“Even\n",
      "if\n",
      "we\n",
      "could\n",
      "keep\n",
      "the\n",
      "machines\n",
      "in\n",
      "a\n",
      "subservient\n",
      "position,\n",
      "for\n",
      "instance,\n",
      "by\n",
      "turning\n",
      "off\n",
      "the\n",
      "power\n",
      "at\n",
      "strategic\n",
      "moments”\n",
      "–\n",
      "and\n",
      "I'll\n",
      "come\n",
      "back\n",
      "to\n",
      "that\n",
      "“turning\n",
      "off\n",
      "the\n",
      "power”\n",
      "idea\n",
      "later\n",
      "on\n",
      "–\n",
      "“we\n",
      "should,\n",
      "as\n",
      "a\n",
      "species,\n",
      "feel\n",
      "greatly\n",
      "humbled.”\n",
      "So\n",
      "who\n",
      "said\n",
      "this?\n",
      "This\n",
      "is\n",
      "Alan\n",
      "Turing\n",
      "in\n",
      "1951.\n",
      "Alan\n",
      "Turing,\n",
      "as\n",
      "you\n",
      "know,\n",
      "is\n",
      "the\n",
      "father\n",
      "of\n",
      "computer\n",
      "science\n",
      "and\n",
      "in\n",
      "many\n",
      "ways,\n",
      "the\n",
      "father\n",
      "of\n",
      "AI\n",
      "as\n",
      "well.\n",
      "So\n",
      "if\n",
      "we\n",
      "think\n",
      "about\n",
      "this\n",
      "problem,\n",
      "the\n",
      "problem\n",
      "of\n",
      "creating\n",
      "something\n",
      "more\n",
      "intelligent\n",
      "than\n",
      "your\n",
      "own\n",
      "species,\n",
      "we\n",
      "might\n",
      "call\n",
      "this\n",
      "“the\n",
      "gorilla\n",
      "problem,”\n",
      "because\n",
      "gorillas'\n",
      "ancestors\n",
      "did\n",
      "this\n",
      "a\n",
      "few\n",
      "million\n",
      "years\n",
      "ago,\n",
      "and\n",
      "now\n",
      "we\n",
      "can\n",
      "ask\n",
      "the\n",
      "gorillas:\n",
      "Was\n",
      "this\n",
      "a\n",
      "good\n",
      "idea?\n",
      "So\n",
      "here\n",
      "they\n",
      "are\n",
      "having\n",
      "a\n",
      "meeting\n",
      "to\n",
      "discuss\n",
      "whether\n",
      "it\n",
      "was\n",
      "a\n",
      "good\n",
      "idea,\n",
      "and\n",
      "after\n",
      "a\n",
      "little\n",
      "while,\n",
      "they\n",
      "conclude,\n",
      "no,\n",
      "this\n",
      "was\n",
      "a\n",
      "terrible\n",
      "idea.\n",
      "Our\n",
      "species\n",
      "is\n",
      "in\n",
      "dire\n",
      "straits.\n",
      "In\n",
      "fact,\n",
      "you\n",
      "can\n",
      "see\n",
      "the\n",
      "existential\n",
      "sadness\n",
      "in\n",
      "their\n",
      "eyes.\n",
      "So\n",
      "this\n",
      "queasy\n",
      "feeling\n",
      "that\n",
      "making\n",
      "something\n",
      "smarter\n",
      "than\n",
      "your\n",
      "own\n",
      "species\n",
      "is\n",
      "maybe\n",
      "not\n",
      "a\n",
      "good\n",
      "idea\n",
      "–\n",
      "what\n",
      "can\n",
      "we\n",
      "do\n",
      "about\n",
      "that?\n",
      "Well,\n",
      "really\n",
      "nothing,\n",
      "except\n",
      "stop\n",
      "doing\n",
      "AI,\n",
      "and\n",
      "because\n",
      "of\n",
      "all\n",
      "the\n",
      "benefits\n",
      "that\n",
      "I\n",
      "mentioned\n",
      "and\n",
      "because\n",
      "I'm\n",
      "an\n",
      "AI\n",
      "researcher,\n",
      "I'm\n",
      "not\n",
      "having\n",
      "that.\n",
      "I\n",
      "actually\n",
      "want\n",
      "to\n",
      "be\n",
      "able\n",
      "to\n",
      "keep\n",
      "doing\n",
      "AI.\n",
      "So\n",
      "we\n",
      "actually\n",
      "need\n",
      "to\n",
      "nail\n",
      "down\n",
      "the\n",
      "problem\n",
      "a\n",
      "bit\n",
      "more.\n",
      "What\n",
      "exactly\n",
      "is\n",
      "the\n",
      "problem?\n",
      "Why\n",
      "is\n",
      "better\n",
      "AI\n",
      "possibly\n",
      "a\n",
      "catastrophe?\n",
      "So\n",
      "here's\n",
      "another\n",
      "quotation:\n",
      "“We\n",
      "had\n",
      "better\n",
      "be\n",
      "quite\n",
      "sure\n",
      "that\n",
      "the\n",
      "purpose\n",
      "put\n",
      "into\n",
      "the\n",
      "machine\n",
      "is\n",
      "the\n",
      "purpose\n",
      "which\n",
      "we\n",
      "really\n",
      "desire.”\n",
      "This\n",
      "was\n",
      "said\n",
      "by\n",
      "Norbert\n",
      "Wiener\n",
      "in\n",
      "1960,\n",
      "shortly\n",
      "after\n",
      "he\n",
      "watched\n",
      "one\n",
      "of\n",
      "the\n",
      "very\n",
      "early\n",
      "learning\n",
      "systems\n",
      "learn\n",
      "to\n",
      "play\n",
      "checkers\n",
      "better\n",
      "than\n",
      "its\n",
      "creator.\n",
      "But\n",
      "this\n",
      "could\n",
      "equally\n",
      "have\n",
      "been\n",
      "said\n",
      "by\n",
      "King\n",
      "Midas.\n",
      "King\n",
      "Midas\n",
      "said,\n",
      "“I\n",
      "want\n",
      "everything\n",
      "I\n",
      "touch\n",
      "to\n",
      "turn\n",
      "to\n",
      "gold,”\n",
      "and\n",
      "he\n",
      "got\n",
      "exactly\n",
      "what\n",
      "he\n",
      "asked\n",
      "for.\n",
      "That\n",
      "was\n",
      "the\n",
      "purpose\n",
      "that\n",
      "he\n",
      "put\n",
      "into\n",
      "the\n",
      "machine,\n",
      "so\n",
      "to\n",
      "speak,\n",
      "and\n",
      "then\n",
      "his\n",
      "food\n",
      "and\n",
      "his\n",
      "drink\n",
      "and\n",
      "his\n",
      "relatives\n",
      "turned\n",
      "to\n",
      "gold\n",
      "and\n",
      "he\n",
      "died\n",
      "in\n",
      "misery\n",
      "and\n",
      "starvation.\n",
      "So\n",
      "we'll\n",
      "call\n",
      "this\n",
      "“the\n",
      "King\n",
      "Midas\n",
      "problem”\n",
      "of\n",
      "stating\n",
      "an\n",
      "objective\n",
      "which\n",
      "is\n",
      "not,\n",
      "in\n",
      "fact,\n",
      "truly\n",
      "aligned\n",
      "with\n",
      "what\n",
      "we\n",
      "want.\n",
      "In\n",
      "modern\n",
      "terms,\n",
      "we\n",
      "call\n",
      "this\n",
      "“the\n",
      "value\n",
      "alignment\n",
      "problem.”\n",
      "Putting\n",
      "in\n",
      "the\n",
      "wrong\n",
      "objective\n",
      "is\n",
      "not\n",
      "the\n",
      "only\n",
      "part\n",
      "of\n",
      "the\n",
      "problem.\n",
      "There's\n",
      "another\n",
      "part.\n",
      "If\n",
      "you\n",
      "put\n",
      "an\n",
      "objective\n",
      "into\n",
      "a\n",
      "machine,\n",
      "even\n",
      "something\n",
      "as\n",
      "simple\n",
      "as,\n",
      "“Fetch\n",
      "the\n",
      "coffee,”\n",
      "the\n",
      "machine\n",
      "says\n",
      "to\n",
      "itself,\n",
      "“Well,\n",
      "how\n",
      "might\n",
      "I\n",
      "fail\n",
      "to\n",
      "fetch\n",
      "the\n",
      "coffee?\n",
      "Someone\n",
      "might\n",
      "switch\n",
      "me\n",
      "off.\n",
      "OK,\n",
      "I\n",
      "have\n",
      "to\n",
      "take\n",
      "steps\n",
      "to\n",
      "prevent\n",
      "that.\n",
      "I\n",
      "will\n",
      "disable\n",
      "my\n",
      "‘off’\n",
      "switch.\n",
      "I\n",
      "will\n",
      "do\n",
      "anything\n",
      "to\n",
      "defend\n",
      "myself\n",
      "against\n",
      "interference\n",
      "with\n",
      "this\n",
      "objective\n",
      "that\n",
      "I\n",
      "have\n",
      "been\n",
      "given.”\n",
      "So\n",
      "this\n",
      "single-minded\n",
      "pursuit\n",
      "in\n",
      "a\n",
      "very\n",
      "defensive\n",
      "mode\n",
      "of\n",
      "an\n",
      "objective\n",
      "that\n",
      "is,\n",
      "in\n",
      "fact,\n",
      "not\n",
      "aligned\n",
      "with\n",
      "the\n",
      "true\n",
      "objectives\n",
      "of\n",
      "the\n",
      "human\n",
      "race\n",
      "–\n",
      "that's\n",
      "the\n",
      "problem\n",
      "that\n",
      "we\n",
      "face.\n",
      "And\n",
      "in\n",
      "fact,\n",
      "that's\n",
      "the\n",
      "high-value\n",
      "takeaway\n",
      "from\n",
      "this\n",
      "talk.\n",
      "If\n",
      "you\n",
      "want\n",
      "to\n",
      "remember\n",
      "one\n",
      "thing,\n",
      "it's\n",
      "that\n",
      "you\n",
      "can't\n",
      "fetch\n",
      "the\n",
      "coffee\n",
      "if\n",
      "you're\n",
      "dead.\n",
      "It's\n",
      "very\n",
      "simple.\n",
      "Just\n",
      "remember\n",
      "that.\n",
      "Repeat\n",
      "it\n",
      "to\n",
      "yourself\n",
      "three\n",
      "times\n",
      "a\n",
      "day.\n",
      "And\n",
      "in\n",
      "fact,\n",
      "this\n",
      "is\n",
      "exactly\n",
      "the\n",
      "plot\n",
      "of\n",
      "“2001:\n",
      "[A\n",
      "Space\n",
      "Odyssey]”\n",
      "HAL\n",
      "has\n",
      "an\n",
      "objective,\n",
      "a\n",
      "mission,\n",
      "which\n",
      "is\n",
      "not\n",
      "aligned\n",
      "with\n",
      "the\n",
      "objectives\n",
      "of\n",
      "the\n",
      "humans,\n",
      "and\n",
      "that\n",
      "leads\n",
      "to\n",
      "this\n",
      "conflict.\n",
      "Now\n",
      "fortunately,\n",
      "HAL\n",
      "is\n",
      "not\n",
      "superintelligent.\n",
      "He's\n",
      "pretty\n",
      "smart,\n",
      "but\n",
      "eventually\n",
      "Dave\n",
      "outwits\n",
      "him\n",
      "and\n",
      "manages\n",
      "to\n",
      "switch\n",
      "him\n",
      "off.\n",
      "But\n",
      "we\n",
      "might\n",
      "not\n",
      "be\n",
      "so\n",
      "lucky.\n",
      "So\n",
      "what\n",
      "are\n",
      "we\n",
      "going\n",
      "to\n",
      "do?\n",
      "I'm\n",
      "trying\n",
      "to\n",
      "redefine\n",
      "AI\n",
      "to\n",
      "get\n",
      "away\n",
      "from\n",
      "this\n",
      "classical\n",
      "notion\n",
      "of\n",
      "machines\n",
      "that\n",
      "intelligently\n",
      "pursue\n",
      "objectives.\n",
      "There\n",
      "are\n",
      "three\n",
      "principles\n",
      "involved.\n",
      "The\n",
      "first\n",
      "one\n",
      "is\n",
      "a\n",
      "principle\n",
      "of\n",
      "altruism,\n",
      "if\n",
      "you\n",
      "like,\n",
      "that\n",
      "the\n",
      "robot's\n",
      "only\n",
      "objective\n",
      "is\n",
      "to\n",
      "maximize\n",
      "the\n",
      "realization\n",
      "of\n",
      "human\n",
      "objectives,\n",
      "of\n",
      "human\n",
      "values.\n",
      "And\n",
      "by\n",
      "values\n",
      "here\n",
      "I\n",
      "don't\n",
      "mean\n",
      "touchy-feely,\n",
      "goody-goody\n",
      "values.\n",
      "I\n",
      "just\n",
      "mean\n",
      "whatever\n",
      "it\n",
      "is\n",
      "that\n",
      "the\n",
      "human\n",
      "would\n",
      "prefer\n",
      "their\n",
      "life\n",
      "to\n",
      "be\n",
      "like.\n",
      "And\n",
      "so\n",
      "this\n",
      "actually\n",
      "violates\n",
      "Asimov's\n",
      "law\n",
      "that\n",
      "the\n",
      "robot\n",
      "has\n",
      "to\n",
      "protect\n",
      "its\n",
      "own\n",
      "existence.\n",
      "It\n",
      "has\n",
      "no\n",
      "interest\n",
      "in\n",
      "preserving\n",
      "its\n",
      "existence\n",
      "whatsoever.\n",
      "The\n",
      "second\n",
      "law\n",
      "is\n",
      "a\n",
      "law\n",
      "of\n",
      "humility,\n",
      "if\n",
      "you\n",
      "like.\n",
      "And\n",
      "this\n",
      "turns\n",
      "out\n",
      "to\n",
      "be\n",
      "really\n",
      "important\n",
      "to\n",
      "make\n",
      "robots\n",
      "safe.\n",
      "It\n",
      "says\n",
      "that\n",
      "the\n",
      "robot\n",
      "does\n",
      "not\n",
      "know\n",
      "what\n",
      "those\n",
      "human\n",
      "values\n",
      "are,\n",
      "so\n",
      "it\n",
      "has\n",
      "to\n",
      "maximize\n",
      "them,\n",
      "but\n",
      "it\n",
      "doesn't\n",
      "know\n",
      "what\n",
      "they\n",
      "are.\n",
      "And\n",
      "that\n",
      "avoids\n",
      "this\n",
      "problem\n",
      "of\n",
      "single-minded\n",
      "pursuit\n",
      "of\n",
      "an\n",
      "objective.\n",
      "This\n",
      "uncertainty\n",
      "turns\n",
      "out\n",
      "to\n",
      "be\n",
      "crucial.\n",
      "Now,\n",
      "in\n",
      "order\n",
      "to\n",
      "be\n",
      "useful\n",
      "to\n",
      "us,\n",
      "it\n",
      "has\n",
      "to\n",
      "have\n",
      "some\n",
      "idea\n",
      "of\n",
      "what\n",
      "we\n",
      "want.\n",
      "It\n",
      "obtains\n",
      "that\n",
      "information\n",
      "primarily\n",
      "by\n",
      "observation\n",
      "of\n",
      "human\n",
      "choices,\n",
      "so\n",
      "our\n",
      "own\n",
      "choices\n",
      "reveal\n",
      "information\n",
      "about\n",
      "what\n",
      "it\n",
      "is\n",
      "that\n",
      "we\n",
      "prefer\n",
      "our\n",
      "lives\n",
      "to\n",
      "be\n",
      "like.\n",
      "So\n",
      "those\n",
      "are\n",
      "the\n",
      "three\n",
      "principles.\n",
      "Let's\n",
      "see\n",
      "how\n",
      "that\n",
      "applies\n",
      "to\n",
      "this\n",
      "question\n",
      "of:\n",
      "“Can\n",
      "you\n",
      "switch\n",
      "the\n",
      "machine\n",
      "off?”\n",
      "as\n",
      "Turing\n",
      "suggested.\n",
      "So\n",
      "here's\n",
      "a\n",
      "PR2\n",
      "robot.\n",
      "This\n",
      "is\n",
      "one\n",
      "that\n",
      "we\n",
      "have\n",
      "in\n",
      "our\n",
      "lab,\n",
      "and\n",
      "it\n",
      "has\n",
      "a\n",
      "big\n",
      "red\n",
      "“off”\n",
      "switch\n",
      "right\n",
      "on\n",
      "the\n",
      "back.\n",
      "The\n",
      "question\n",
      "is:\n",
      "Is\n",
      "it\n",
      "going\n",
      "to\n",
      "let\n",
      "you\n",
      "switch\n",
      "it\n",
      "off?\n",
      "If\n",
      "we\n",
      "do\n",
      "it\n",
      "the\n",
      "classical\n",
      "way,\n",
      "we\n",
      "give\n",
      "it\n",
      "the\n",
      "objective\n",
      "of,\n",
      "“Fetch\n",
      "the\n",
      "coffee,\n",
      "I\n",
      "must\n",
      "fetch\n",
      "the\n",
      "coffee,\n",
      "I\n",
      "can't\n",
      "fetch\n",
      "the\n",
      "coffee\n",
      "if\n",
      "I'm\n",
      "dead,”\n",
      "so\n",
      "obviously\n",
      "the\n",
      "PR2\n",
      "has\n",
      "been\n",
      "listening\n",
      "to\n",
      "my\n",
      "talk,\n",
      "and\n",
      "so\n",
      "it\n",
      "says,\n",
      "therefore,\n",
      "“I\n",
      "must\n",
      "disable\n",
      "my\n",
      "‘off’\n",
      "switch,\n",
      "and\n",
      "probably\n",
      "taser\n",
      "all\n",
      "the\n",
      "other\n",
      "people\n",
      "in\n",
      "Starbucks\n",
      "who\n",
      "might\n",
      "interfere\n",
      "with\n",
      "me.”\n",
      "So\n",
      "this\n",
      "seems\n",
      "to\n",
      "be\n",
      "inevitable,\n",
      "right?\n",
      "This\n",
      "kind\n",
      "of\n",
      "failure\n",
      "mode\n",
      "seems\n",
      "to\n",
      "be\n",
      "inevitable,\n",
      "and\n",
      "it\n",
      "follows\n",
      "from\n",
      "having\n",
      "a\n",
      "concrete,\n",
      "definite\n",
      "objective.\n",
      "So\n",
      "what\n",
      "happens\n",
      "if\n",
      "the\n",
      "machine\n",
      "is\n",
      "uncertain\n",
      "about\n",
      "the\n",
      "objective?\n",
      "Well,\n",
      "it\n",
      "reasons\n",
      "in\n",
      "a\n",
      "different\n",
      "way.\n",
      "It\n",
      "says,\n",
      "“OK,\n",
      "the\n",
      "human\n",
      "might\n",
      "switch\n",
      "me\n",
      "off,\n",
      "but\n",
      "only\n",
      "if\n",
      "I'm\n",
      "doing\n",
      "something\n",
      "wrong.\n",
      "Well,\n",
      "I\n",
      "don't\n",
      "really\n",
      "know\n",
      "what\n",
      "wrong\n",
      "is,\n",
      "but\n",
      "I\n",
      "know\n",
      "that\n",
      "I\n",
      "don't\n",
      "want\n",
      "to\n",
      "do\n",
      "it.”\n",
      "So\n",
      "that's\n",
      "the\n",
      "first\n",
      "and\n",
      "second\n",
      "principles\n",
      "right\n",
      "there.\n",
      "“So\n",
      "I\n",
      "should\n",
      "let\n",
      "the\n",
      "human\n",
      "switch\n",
      "me\n",
      "off.”\n",
      "And\n",
      "in\n",
      "fact\n",
      "you\n",
      "can\n",
      "calculate\n",
      "the\n",
      "incentive\n",
      "that\n",
      "the\n",
      "robot\n",
      "has\n",
      "to\n",
      "allow\n",
      "the\n",
      "human\n",
      "to\n",
      "switch\n",
      "it\n",
      "off,\n",
      "and\n",
      "it's\n",
      "directly\n",
      "tied\n",
      "to\n",
      "the\n",
      "degree\n",
      "of\n",
      "uncertainty\n",
      "about\n",
      "the\n",
      "underlying\n",
      "objective.\n",
      "And\n",
      "then\n",
      "when\n",
      "the\n",
      "machine\n",
      "is\n",
      "switched\n",
      "off,\n",
      "that\n",
      "third\n",
      "principle\n",
      "comes\n",
      "into\n",
      "play.\n",
      "It\n",
      "learns\n",
      "something\n",
      "about\n",
      "the\n",
      "objectives\n",
      "it\n",
      "should\n",
      "be\n",
      "pursuing,\n",
      "because\n",
      "it\n",
      "learns\n",
      "that\n",
      "what\n",
      "it\n",
      "did\n",
      "wasn't\n",
      "right.\n",
      "In\n",
      "fact,\n",
      "we\n",
      "can,\n",
      "with\n",
      "suitable\n",
      "use\n",
      "of\n",
      "Greek\n",
      "symbols,\n",
      "as\n",
      "mathematicians\n",
      "usually\n",
      "do,\n",
      "we\n",
      "can\n",
      "actually\n",
      "prove\n",
      "a\n",
      "theorem\n",
      "that\n",
      "says\n",
      "that\n",
      "such\n",
      "a\n",
      "robot\n",
      "is\n",
      "provably\n",
      "beneficial\n",
      "to\n",
      "the\n",
      "human.\n",
      "You\n",
      "are\n",
      "provably\n",
      "better\n",
      "off\n",
      "with\n",
      "a\n",
      "machine\n",
      "that's\n",
      "designed\n",
      "in\n",
      "this\n",
      "way\n",
      "than\n",
      "without\n",
      "it.\n",
      "So\n",
      "this\n",
      "is\n",
      "a\n",
      "very\n",
      "simple\n",
      "example,\n",
      "but\n",
      "this\n",
      "is\n",
      "the\n",
      "first\n",
      "step\n",
      "in\n",
      "what\n",
      "we're\n",
      "trying\n",
      "to\n",
      "do\n",
      "with\n",
      "human-compatible\n",
      "AI.\n",
      "Now,\n",
      "this\n",
      "third\n",
      "principle,\n",
      "I\n",
      "think\n",
      "is\n",
      "the\n",
      "one\n",
      "that\n",
      "you're\n",
      "probably\n",
      "scratching\n",
      "your\n",
      "head\n",
      "over.\n",
      "You're\n",
      "probably\n",
      "thinking,\n",
      "“Well,\n",
      "you\n",
      "know,\n",
      "I\n",
      "behave\n",
      "badly.\n",
      "I\n",
      "don't\n",
      "want\n",
      "my\n",
      "robot\n",
      "to\n",
      "behave\n",
      "like\n",
      "me.\n",
      "I\n",
      "sneak\n",
      "down\n",
      "in\n",
      "the\n",
      "middle\n",
      "of\n",
      "the\n",
      "night\n",
      "and\n",
      "take\n",
      "stuff\n",
      "from\n",
      "the\n",
      "fridge.\n",
      "I\n",
      "do\n",
      "this\n",
      "and\n",
      "that.”\n",
      "There's\n",
      "all\n",
      "kinds\n",
      "of\n",
      "things\n",
      "you\n",
      "don't\n",
      "want\n",
      "the\n",
      "robot\n",
      "doing.\n",
      "But\n",
      "in\n",
      "fact,\n",
      "it\n",
      "doesn't\n",
      "quite\n",
      "work\n",
      "that\n",
      "way.\n",
      "Just\n",
      "because\n",
      "you\n",
      "behave\n",
      "badly\n",
      "doesn't\n",
      "mean\n",
      "the\n",
      "robot\n",
      "is\n",
      "going\n",
      "to\n",
      "copy\n",
      "your\n",
      "behavior.\n",
      "It's\n",
      "going\n",
      "to\n",
      "understand\n",
      "your\n",
      "motivations\n",
      "and\n",
      "maybe\n",
      "help\n",
      "you\n",
      "resist\n",
      "them,\n",
      "if\n",
      "appropriate.\n",
      "But\n",
      "it's\n",
      "still\n",
      "difficult.\n",
      "What\n",
      "we're\n",
      "trying\n",
      "to\n",
      "do,\n",
      "in\n",
      "fact,\n",
      "is\n",
      "to\n",
      "allow\n",
      "machines\n",
      "to\n",
      "predict\n",
      "for\n",
      "any\n",
      "person\n",
      "and\n",
      "for\n",
      "any\n",
      "possible\n",
      "life\n",
      "that\n",
      "they\n",
      "could\n",
      "live,\n",
      "and\n",
      "the\n",
      "lives\n",
      "of\n",
      "everybody\n",
      "else:\n",
      "Which\n",
      "would\n",
      "they\n",
      "prefer?\n",
      "And\n",
      "there\n",
      "are\n",
      "many,\n",
      "many\n",
      "difficulties\n",
      "involved\n",
      "in\n",
      "doing\n",
      "this;\n",
      "I\n",
      "don't\n",
      "expect\n",
      "that\n",
      "this\n",
      "is\n",
      "going\n",
      "to\n",
      "get\n",
      "solved\n",
      "very\n",
      "quickly.\n",
      "The\n",
      "real\n",
      "difficulties,\n",
      "in\n",
      "fact,\n",
      "are\n",
      "us.\n",
      "As\n",
      "I\n",
      "have\n",
      "already\n",
      "mentioned,\n",
      "we\n",
      "behave\n",
      "badly.\n",
      "In\n",
      "fact,\n",
      "some\n",
      "of\n",
      "us\n",
      "are\n",
      "downright\n",
      "nasty.\n",
      "Now\n",
      "the\n",
      "robot,\n",
      "as\n",
      "I\n",
      "said,\n",
      "doesn't\n",
      "have\n",
      "to\n",
      "copy\n",
      "the\n",
      "behavior.\n",
      "The\n",
      "robot\n",
      "does\n",
      "not\n",
      "have\n",
      "any\n",
      "objective\n",
      "of\n",
      "its\n",
      "own.\n",
      "It's\n",
      "purely\n",
      "altruistic.\n",
      "And\n",
      "it's\n",
      "not\n",
      "designed\n",
      "just\n",
      "to\n",
      "satisfy\n",
      "the\n",
      "desires\n",
      "of\n",
      "one\n",
      "person,\n",
      "the\n",
      "user,\n",
      "but\n",
      "in\n",
      "fact\n",
      "it\n",
      "has\n",
      "to\n",
      "respect\n",
      "the\n",
      "preferences\n",
      "of\n",
      "everybody.\n",
      "So\n",
      "it\n",
      "can\n",
      "deal\n",
      "with\n",
      "a\n",
      "certain\n",
      "amount\n",
      "of\n",
      "nastiness,\n",
      "and\n",
      "it\n",
      "can\n",
      "even\n",
      "understand\n",
      "that\n",
      "your\n",
      "nastiness,\n",
      "for\n",
      "example,\n",
      "you\n",
      "may\n",
      "take\n",
      "bribes\n",
      "as\n",
      "a\n",
      "passport\n",
      "official\n",
      "because\n",
      "you\n",
      "need\n",
      "to\n",
      "feed\n",
      "your\n",
      "family\n",
      "and\n",
      "send\n",
      "your\n",
      "kids\n",
      "to\n",
      "school.\n",
      "It\n",
      "can\n",
      "understand\n",
      "that;\n",
      "it\n",
      "doesn't\n",
      "mean\n",
      "it's\n",
      "going\n",
      "to\n",
      "steal.\n",
      "In\n",
      "fact,\n",
      "it'll\n",
      "just\n",
      "help\n",
      "you\n",
      "send\n",
      "your\n",
      "kids\n",
      "to\n",
      "school.\n",
      "We\n",
      "are\n",
      "also\n",
      "computationally\n",
      "limited.\n",
      "Lee\n",
      "Sedol\n",
      "is\n",
      "a\n",
      "brilliant\n",
      "Go\n",
      "player,\n",
      "but\n",
      "he\n",
      "still\n",
      "lost.\n",
      "So\n",
      "if\n",
      "we\n",
      "look\n",
      "at\n",
      "his\n",
      "actions,\n",
      "he\n",
      "took\n",
      "an\n",
      "action\n",
      "that\n",
      "lost\n",
      "the\n",
      "game.\n",
      "That\n",
      "doesn't\n",
      "mean\n",
      "he\n",
      "wanted\n",
      "to\n",
      "lose.\n",
      "So\n",
      "to\n",
      "understand\n",
      "his\n",
      "behavior,\n",
      "we\n",
      "actually\n",
      "have\n",
      "to\n",
      "invert\n",
      "through\n",
      "a\n",
      "model\n",
      "of\n",
      "human\n",
      "cognition\n",
      "that\n",
      "includes\n",
      "our\n",
      "computational\n",
      "limitations\n",
      "–\n",
      "a\n",
      "very\n",
      "complicated\n",
      "model.\n",
      "But\n",
      "it's\n",
      "still\n",
      "something\n",
      "that\n",
      "we\n",
      "can\n",
      "work\n",
      "on\n",
      "understanding.\n",
      "Probably\n",
      "the\n",
      "most\n",
      "difficult\n",
      "part,\n",
      "from\n",
      "my\n",
      "point\n",
      "of\n",
      "view\n",
      "as\n",
      "an\n",
      "AI\n",
      "researcher,\n",
      "is\n",
      "the\n",
      "fact\n",
      "that\n",
      "there\n",
      "are\n",
      "lots\n",
      "of\n",
      "us,\n",
      "and\n",
      "so\n",
      "the\n",
      "machine\n",
      "has\n",
      "to\n",
      "somehow\n",
      "trade\n",
      "off,\n",
      "weigh\n",
      "up\n",
      "the\n",
      "preferences\n",
      "of\n",
      "many\n",
      "different\n",
      "people,\n",
      "and\n",
      "there\n",
      "are\n",
      "different\n",
      "ways\n",
      "to\n",
      "do\n",
      "that.\n",
      "Economists,\n",
      "sociologists,\n",
      "moral\n",
      "philosophers\n",
      "have\n",
      "understood\n",
      "that,\n",
      "and\n",
      "we\n",
      "are\n",
      "actively\n",
      "looking\n",
      "for\n",
      "collaboration.\n",
      "Let's\n",
      "have\n",
      "a\n",
      "look\n",
      "and\n",
      "see\n",
      "what\n",
      "happens\n",
      "when\n",
      "you\n",
      "get\n",
      "that\n",
      "wrong.\n",
      "So\n",
      "you\n",
      "can\n",
      "have\n",
      "a\n",
      "conversation,\n",
      "for\n",
      "example,\n",
      "with\n",
      "your\n",
      "intelligent\n",
      "personal\n",
      "assistant\n",
      "that\n",
      "might\n",
      "be\n",
      "available\n",
      "in\n",
      "a\n",
      "few\n",
      "years'\n",
      "time.\n",
      "Think\n",
      "of\n",
      "a\n",
      "Siri\n",
      "on\n",
      "steroids.\n",
      "So\n",
      "Siri\n",
      "says,\n",
      "“Your\n",
      "wife\n",
      "called\n",
      "to\n",
      "remind\n",
      "you\n",
      "about\n",
      "dinner\n",
      "tonight.”\n",
      "And\n",
      "of\n",
      "course,\n",
      "you've\n",
      "forgotten.\n",
      "“What?\n",
      "What\n",
      "dinner?\n",
      "What\n",
      "are\n",
      "you\n",
      "talking\n",
      "about?”\n",
      "“Uh,\n",
      "your\n",
      "20th\n",
      "anniversary\n",
      "at\n",
      "7pm.”\n",
      "\"I\n",
      "can't\n",
      "do\n",
      "that.\n",
      "I'm\n",
      "meeting\n",
      "with\n",
      "the\n",
      "secretary-general\n",
      "at\n",
      "7:30.\n",
      "How\n",
      "could\n",
      "this\n",
      "have\n",
      "happened?\"\n",
      "“Well,\n",
      "I\n",
      "did\n",
      "warn\n",
      "you,\n",
      "but\n",
      "you\n",
      "overrode\n",
      "my\n",
      "recommendation.”\n",
      "“Well,\n",
      "what\n",
      "am\n",
      "I\n",
      "going\n",
      "to\n",
      "do?\n",
      "I\n",
      "can't\n",
      "just\n",
      "tell\n",
      "him\n",
      "I'm\n",
      "too\n",
      "busy.”\n",
      "“Don't\n",
      "worry.\n",
      "I\n",
      "arranged\n",
      "for\n",
      "his\n",
      "plane\n",
      "to\n",
      "be\n",
      "delayed.”\n",
      "“Some\n",
      "kind\n",
      "of\n",
      "computer\n",
      "malfunction.”\n",
      "“Really?\n",
      "You\n",
      "can\n",
      "do\n",
      "that?”\n",
      "“He\n",
      "sends\n",
      "his\n",
      "profound\n",
      "apologies\n",
      "and\n",
      "looks\n",
      "forward\n",
      "to\n",
      "meeting\n",
      "you\n",
      "for\n",
      "lunch\n",
      "tomorrow.”\n",
      "So\n",
      "the\n",
      "values\n",
      "here\n",
      "–\n",
      "there's\n",
      "a\n",
      "slight\n",
      "mistake\n",
      "going\n",
      "on.\n",
      "This\n",
      "is\n",
      "clearly\n",
      "following\n",
      "my\n",
      "wife's\n",
      "values\n",
      "which\n",
      "is\n",
      "“Happy\n",
      "wife,\n",
      "happy\n",
      "life.”\n",
      "It\n",
      "could\n",
      "go\n",
      "the\n",
      "other\n",
      "way.\n",
      "You\n",
      "could\n",
      "come\n",
      "home\n",
      "after\n",
      "a\n",
      "hard\n",
      "day's\n",
      "work,\n",
      "and\n",
      "the\n",
      "computer\n",
      "says,\n",
      "“Long\n",
      "day?”\n",
      "“Yes,\n",
      "I\n",
      "didn't\n",
      "even\n",
      "have\n",
      "time\n",
      "for\n",
      "lunch.”\n",
      "“You\n",
      "must\n",
      "be\n",
      "very\n",
      "hungry.”\n",
      "“Starving,\n",
      "yeah.\n",
      "Could\n",
      "you\n",
      "make\n",
      "some\n",
      "dinner?”\n",
      "“There's\n",
      "something\n",
      "I\n",
      "need\n",
      "to\n",
      "tell\n",
      "you.”\n",
      "“There\n",
      "are\n",
      "humans\n",
      "in\n",
      "South\n",
      "Sudan\n",
      "who\n",
      "are\n",
      "in\n",
      "more\n",
      "urgent\n",
      "need\n",
      "than\n",
      "you.”\n",
      "“So\n",
      "I'm\n",
      "leaving.\n",
      "Make\n",
      "your\n",
      "own\n",
      "dinner.”\n",
      "So\n",
      "we\n",
      "have\n",
      "to\n",
      "solve\n",
      "these\n",
      "problems,\n",
      "and\n",
      "I'm\n",
      "looking\n",
      "forward\n",
      "to\n",
      "working\n",
      "on\n",
      "them.\n",
      "There\n",
      "are\n",
      "reasons\n",
      "for\n",
      "optimism.\n",
      "One\n",
      "reason\n",
      "is,\n",
      "there\n",
      "is\n",
      "a\n",
      "massive\n",
      "amount\n",
      "of\n",
      "data.\n",
      "Because\n",
      "remember\n",
      "–\n",
      "I\n",
      "said\n",
      "they're\n",
      "going\n",
      "to\n",
      "read\n",
      "everything\n",
      "the\n",
      "human\n",
      "race\n",
      "has\n",
      "ever\n",
      "written.\n",
      "Most\n",
      "of\n",
      "what\n",
      "we\n",
      "write\n",
      "about\n",
      "is\n",
      "human\n",
      "beings\n",
      "doing\n",
      "things\n",
      "and\n",
      "other\n",
      "people\n",
      "getting\n",
      "upset\n",
      "about\n",
      "it.\n",
      "So\n",
      "there's\n",
      "a\n",
      "massive\n",
      "amount\n",
      "of\n",
      "data\n",
      "to\n",
      "learn\n",
      "from.\n",
      "There's\n",
      "also\n",
      "a\n",
      "very\n",
      "strong\n",
      "economic\n",
      "incentive\n",
      "to\n",
      "get\n",
      "this\n",
      "right.\n",
      "So\n",
      "imagine\n",
      "your\n",
      "domestic\n",
      "robot's\n",
      "at\n",
      "home.\n",
      "You're\n",
      "late\n",
      "from\n",
      "work\n",
      "again\n",
      "and\n",
      "the\n",
      "robot\n",
      "has\n",
      "to\n",
      "feed\n",
      "the\n",
      "kids,\n",
      "and\n",
      "the\n",
      "kids\n",
      "are\n",
      "hungry\n",
      "and\n",
      "there's\n",
      "nothing\n",
      "in\n",
      "the\n",
      "fridge.\n",
      "And\n",
      "the\n",
      "robot\n",
      "sees\n",
      "the\n",
      "cat.\n",
      "And\n",
      "the\n",
      "robot\n",
      "hasn't\n",
      "quite\n",
      "learned\n",
      "the\n",
      "human\n",
      "value\n",
      "function\n",
      "properly,\n",
      "so\n",
      "it\n",
      "doesn't\n",
      "understand\n",
      "the\n",
      "sentimental\n",
      "value\n",
      "of\n",
      "the\n",
      "cat\n",
      "outweighs\n",
      "the\n",
      "nutritional\n",
      "value\n",
      "of\n",
      "the\n",
      "cat.\n",
      "So\n",
      "then\n",
      "what\n",
      "happens?\n",
      "Well,\n",
      "it\n",
      "happens\n",
      "like\n",
      "this:\n",
      "“Deranged\n",
      "robot\n",
      "cooks\n",
      "kitty\n",
      "for\n",
      "family\n",
      "dinner.”\n",
      "That\n",
      "one\n",
      "incident\n",
      "would\n",
      "be\n",
      "the\n",
      "end\n",
      "of\n",
      "the\n",
      "domestic\n",
      "robot\n",
      "industry.\n",
      "So\n",
      "there's\n",
      "a\n",
      "huge\n",
      "incentive\n",
      "to\n",
      "get\n",
      "this\n",
      "right\n",
      "long\n",
      "before\n",
      "we\n",
      "reach\n",
      "superintelligent\n",
      "machines.\n",
      "So\n",
      "to\n",
      "summarize:\n",
      "I'm\n",
      "actually\n",
      "trying\n",
      "to\n",
      "change\n",
      "the\n",
      "definition\n",
      "of\n",
      "AI\n",
      "so\n",
      "that\n",
      "we\n",
      "have\n",
      "provably\n",
      "beneficial\n",
      "machines.\n",
      "And\n",
      "the\n",
      "principles\n",
      "are:\n",
      "machines\n",
      "that\n",
      "are\n",
      "altruistic,\n",
      "that\n",
      "want\n",
      "to\n",
      "achieve\n",
      "only\n",
      "our\n",
      "objectives,\n",
      "but\n",
      "that\n",
      "are\n",
      "uncertain\n",
      "about\n",
      "what\n",
      "those\n",
      "objectives\n",
      "are,\n",
      "and\n",
      "will\n",
      "watch\n",
      "all\n",
      "of\n",
      "us\n",
      "to\n",
      "learn\n",
      "more\n",
      "about\n",
      "what\n",
      "it\n",
      "is\n",
      "that\n",
      "we\n",
      "really\n",
      "want.\n",
      "And\n",
      "hopefully\n",
      "in\n",
      "the\n",
      "process,\n",
      "we\n",
      "will\n",
      "learn\n",
      "to\n",
      "be\n",
      "better\n",
      "people.\n",
      "Thank\n",
      "you\n",
      "very\n",
      "much.\n",
      "Chris\n",
      "Anderson:\n",
      "So\n",
      "interesting,\n",
      "Stuart.\n",
      "We're\n",
      "going\n",
      "to\n",
      "stand\n",
      "here\n",
      "a\n",
      "bit\n",
      "because\n",
      "I\n",
      "think\n",
      "they're\n",
      "setting\n",
      "up\n",
      "for\n",
      "our\n",
      "next\n",
      "speaker.\n",
      "A\n",
      "couple\n",
      "of\n",
      "questions.\n",
      "So\n",
      "the\n",
      "idea\n",
      "of\n",
      "programming\n",
      "in\n",
      "ignorance\n",
      "seems\n",
      "intuitively\n",
      "really\n",
      "powerful.\n",
      "As\n",
      "you\n",
      "get\n",
      "to\n",
      "superintelligence,\n",
      "what's\n",
      "going\n",
      "to\n",
      "stop\n",
      "a\n",
      "robot\n",
      "reading\n",
      "literature\n",
      "and\n",
      "discovering\n",
      "this\n",
      "idea\n",
      "that\n",
      "knowledge\n",
      "is\n",
      "actually\n",
      "better\n",
      "than\n",
      "ignorance\n",
      "and\n",
      "still\n",
      "just\n",
      "shifting\n",
      "its\n",
      "own\n",
      "goals\n",
      "and\n",
      "rewriting\n",
      "that\n",
      "programming?\n",
      "Stuart\n",
      "Russell:\n",
      "Yes,\n",
      "so\n",
      "we\n",
      "want\n",
      "it\n",
      "to\n",
      "learn\n",
      "more,\n",
      "as\n",
      "I\n",
      "said,\n",
      "about\n",
      "our\n",
      "objectives.\n",
      "It'll\n",
      "only\n",
      "become\n",
      "more\n",
      "certain\n",
      "as\n",
      "it\n",
      "becomes\n",
      "more\n",
      "correct,\n",
      "so\n",
      "the\n",
      "evidence\n",
      "is\n",
      "there\n",
      "and\n",
      "it's\n",
      "going\n",
      "to\n",
      "be\n",
      "designed\n",
      "to\n",
      "interpret\n",
      "it\n",
      "correctly.\n",
      "It\n",
      "will\n",
      "understand,\n",
      "for\n",
      "example,\n",
      "that\n",
      "books\n",
      "are\n",
      "very\n",
      "biased\n",
      "in\n",
      "the\n",
      "evidence\n",
      "they\n",
      "contain.\n",
      "They\n",
      "only\n",
      "talk\n",
      "about\n",
      "kings\n",
      "and\n",
      "princes\n",
      "and\n",
      "elite\n",
      "white\n",
      "male\n",
      "people\n",
      "doing\n",
      "stuff.\n",
      "So\n",
      "it's\n",
      "a\n",
      "complicated\n",
      "problem,\n",
      "but\n",
      "as\n",
      "it\n",
      "learns\n",
      "more\n",
      "about\n",
      "our\n",
      "objectives\n",
      "it\n",
      "will\n",
      "become\n",
      "more\n",
      "and\n",
      "more\n",
      "useful\n",
      "to\n",
      "us.\n",
      "CA:\n",
      "And\n",
      "you\n",
      "couldn't\n",
      "just\n",
      "boil\n",
      "it\n",
      "down\n",
      "to\n",
      "one\n",
      "law,\n",
      "you\n",
      "know,\n",
      "hardwired\n",
      "in:\n",
      "“if\n",
      "any\n",
      "human\n",
      "ever\n",
      "tries\n",
      "to\n",
      "switch\n",
      "me\n",
      "off,\n",
      "I\n",
      "comply.\n",
      "I\n",
      "comply.”\n",
      "SR:\n",
      "Absolutely\n",
      "not.\n",
      "That\n",
      "would\n",
      "be\n",
      "a\n",
      "terrible\n",
      "idea.\n",
      "So\n",
      "imagine\n",
      "that\n",
      "you\n",
      "have\n",
      "a\n",
      "self-driving\n",
      "car\n",
      "and\n",
      "you\n",
      "want\n",
      "to\n",
      "send\n",
      "your\n",
      "five-year-old\n",
      "off\n",
      "to\n",
      "preschool.\n",
      "Do\n",
      "you\n",
      "want\n",
      "your\n",
      "five-year-old\n",
      "to\n",
      "be\n",
      "able\n",
      "to\n",
      "switch\n",
      "off\n",
      "the\n",
      "car\n",
      "while\n",
      "it's\n",
      "driving\n",
      "along?\n",
      "Probably\n",
      "not.\n",
      "So\n",
      "it\n",
      "needs\n",
      "to\n",
      "understand\n",
      "how\n",
      "rational\n",
      "and\n",
      "sensible\n",
      "the\n",
      "person\n",
      "is.\n",
      "The\n",
      "more\n",
      "rational\n",
      "the\n",
      "person,\n",
      "the\n",
      "more\n",
      "willing\n",
      "you\n",
      "are\n",
      "to\n",
      "be\n",
      "switched\n",
      "off.\n",
      "If\n",
      "the\n",
      "person\n",
      "is\n",
      "completely\n",
      "random\n",
      "or\n",
      "even\n",
      "malicious,\n",
      "then\n",
      "you're\n",
      "less\n",
      "willing\n",
      "to\n",
      "be\n",
      "switched\n",
      "off.\n",
      "CA:\n",
      "All\n",
      "right.\n",
      "Stuart,\n",
      "can\n",
      "I\n",
      "just\n",
      "say,\n",
      "I\n",
      "really,\n",
      "really\n",
      "hope\n",
      "you\n",
      "figure\n",
      "this\n",
      "out\n",
      "for\n",
      "us.\n",
      "Thank\n",
      "you\n",
      "so\n",
      "much\n",
      "for\n",
      "that\n",
      "talk.\n",
      "That\n",
      "was\n",
      "amazing.\n",
      "SR:\n",
      "Thank\n",
      "you.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prt('D',X[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_transcript = [' '.join([idx2word[i] for i in h]) for h in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You've heard of your I.Q., your general intelligence, but what's your Psy-Q? How much do you know about what makes you tick, and how good are you at predicting other people's behavior or even your own? And how much of what you think you know about psychology is wrong? Let's find out by counting down the top 10 myths of psychology. You've probably heard it said that when it comes to their psychology, it's almost as if men are from Mars and women are from Venus. But how different are men and women really? To find out, let's start by looking at something on which men and women really do differ and plotting some psychological gender differences on the same scale. One thing men and women do really differ on is how far they can throw a ball. So if we look at the data for men here, we see what is called a normal distribution curve. A few men can throw a ball really far, and a few men not far at all, but most a kind of average distance. And women share the same distribution as well, but actually there's quite a big difference. In fact, the average man can throw a ball further than about 98 percent of all women. So now let's look at what some psychological gender differences look like on the same standardized scale. Any psychologist will tell you that men are better at spatial awareness than women – so things like map-reading, for example – and it's true, but let's have a look at the size of this difference. It's tiny; the lines are so close together they almost overlap. In fact, the average woman is better than 33 percent of all men, and of course, if that was 50 percent, then the two genders would be exactly equal. It's worth bearing in mind that this difference and the next one I'll show you are pretty much the biggest psychological gender differences ever discovered in psychology. So here's the next one. Any psychologist will tell you that women are better with language and grammar than men. So here's performance on the standardized grammar test. There go the women. There go the men. Again, yes, women are better on average, but the lines are so close that 33 percent of men are better than the average woman, and again, if it was 50 percent, that would represent complete gender equality. So it's not really a case of Mars and Venus. It's more a case of, if anything, Mars and Snickers: basically the same, but one's maybe slightly nuttier than the other. I won't say which. Now we've got you warmed up. Let's psychoanalyze you using the famous Rorschach inkblot test. So you can probably see two, I dunno, two bears or two people or something. But what do you think they're doing? Put your hand up if you think they're saying hello. Not many people. Okay. Put your hands up if you think they are high-fiving. Okay. What if you think they're fighting? Only a few people there. Okay, so if you think they're saying hello or high-fiving, then that means you're a friendly person. If you think they're fighting, you're a bit more of a nasty, aggressive person. Are you a lover or a fighter, basically. What about this one? This isn't really a voting one, so on three everyone shout out what you see. One, two, three. (Audience shouting) I heard hamster. Who said hamster? That was very worrying. A guy there said hamster. Well, you should see some kind of two-legged animal here, and then the mirror image of them there. If you didn't, then this means that you have difficulty processing complex situations where there's a lot going on. Except, of course, it doesn't mean that at all. Rorschach inkblot tests have basically no validity when it comes to diagnosing people's personality and are not used by modern-day psychologists. In fact, one recent study found that when you do try to diagnose people's personalities using Rorschach inkblot tests, schizophrenia was diagnosed in about one sixth of apparently perfectly normal participants. So if you didn't do that well on this, maybe you are not a very visual type of person. So let's do another quick quiz to find out. When making a cake, do you prefer to – so hands up for each one again – do you prefer to use a recipe book with pictures? Yeah, a few people. Have a friend talk you through? Or have a go, making it up as you go along? Quite a few people there. Okay, so if you said A, then this means that you are a visual learner and you learn best when information is presented in a visual style. If you said B, it means you're an auditory learner, that you learn best when information is presented to you in an auditory format. And if you said C, it means that you're a kinesthetic learner, that you learn best when you get stuck in and do things with your hands. Except, of course, as you've probably guessed, that it doesn't, because the whole thing is a complete myth. Learning styles are made up and are not supported by scientific evidence. So we know this because in tightly controlled experimental studies, when learners are given material to learn either in their preferred style or an opposite style, it makes no difference at all to the amount of information that they retain. And if you think about it for just a second, it's just obvious that this has to be true. It's obvious that the best presentation format depends not on you, but on what you're trying to learn. Could you learn to drive a car, for example, just by listening to someone telling you what to do with no kinesthetic experience? Could you solve simultaneous equations by talking them through in your head and without writing them down? Could you revise for your architecture exams using interpretive dance if you're a kinesthetic learner? No. What you need to do is match the material to be learned to the presentation format, not you. I know many of you are A-level students that will have recently gotten your GCSE results. And if you didn't quite get what you were hoping for, then you can't really blame your learning style, but one thing that you might want to think about blaming is your genes. So what this is all about is a recent study at University College London found that 58 percent of the variation between different students and their GCSE results was down to genetic factors. That sounds like a very precise figure, so how can we tell? Well, when we want to unpack the relative contributions of genes and the environment, what we can do is do a twin study. So identical twins share 100 percent of their environment and 100 percent of their genes, whereas non-identical twins share 100 percent of their environment, but just like any brother and sister, share only 50 percent of their genes. So by comparing how similar GCSE results are in identical twins versus non-identical twins, and doing some clever math, we can an idea of how much variation and performance is due to the environment and how much is due to genes. And it turns out that it's about 58 percent due to genes. So this isn't to undermine the hard work that you and your teachers here put in. If you didn't quite get the GCSE results that you were hoping for, then you can always try blaming your parents, or at least their genes. One thing that you shouldn't blame is being a left-brained or right-brained learner, because again, this is a myth. So the myth here is that the left brain is logical, it's good with equations like this, and the right brain is more creative, so the right brain is better at music. But again, this is a myth because nearly everything that you do involves nearly all parts of your brain talking together, even just the most mundane thing like having a normal conversation. However, perhaps one reason why this myth has survived is that there is a slight grain of truth to it. So a related version of the myth is that left-handed people are more creative than right-handed people, which kind of makes sense because your brain controls the opposite hands, so left-handed people, the right side of the brain is slightly more active than the left-hand side of the brain, and the idea is the right-hand side is more creative. Now, it isn't true per se that left-handed people are more creative than right-handed people. What is true that ambidextrous people, or people who use both hands for different tasks, are more creative thinkers than one-handed people, because being ambidextrous involves having both sides of the brain talk to each other a lot, which seems to be involved in creating flexible thinking. The myth of the creative left-hander arises from the fact that being ambidextrous is more common amongst left-handers than right-handers, so a grain of truth in the idea of the creative left-hander, but not much. A related myth that you've probably heard of is that we only use 10 percent of our brains. This is, again, a complete myth. Nearly everything that we do, even the most mundane thing, uses nearly all of our brains. That said, it is of course true that most of us don't use our brainpower quite as well as we could. So what could we do to boost our brainpower? Maybe we could listen to a nice bit of Mozart. Have you heard of the idea of the Mozart effect? So the idea is that listening to Mozart makes you smarter and improves your performance on I.Q. tests. Now again, what's interesting about this myth is that although it's basically a myth, there is a grain of truth to it. So the original study found that participants who were played Mozart music for a few minutes did better on a subsequent I.Q. test than participants who simply sat in silence. But a follow-up study recruited some people who liked Mozart music and then another group of people who were fans of the horror stories of Stephen King. And they played the people the music or the stories. The people who preferred Mozart music to the stories got a bigger I.Q. boost from the Mozart than the stories, but the people who preferred the stories to the Mozart music got a bigger I.Q. boost from listening to the Stephen King stories than the Mozart music. So the truth is that listening to something that you enjoy perks you up a bit and gives you a temporary I.Q. boost on a narrow range of tasks. There's no suggestion that listening to Mozart, or indeed Stephen King stories, is going to make you any smarter in the long run. Another version of the Mozart myth is that listening to Mozart can make you not only cleverer but healthier, too. Unfortunately, this doesn't seem to be true of someone who listened to the music of Mozart almost every day, Mozart himself, who suffered from gonorrhea, smallpox, arthritis, and, what most people think eventually killed him in the end, syphilis. This suggests that Mozart should have bit more careful, perhaps, when choosing his sexual partners. But how do we choose a partner? So a myth that I have to say is sometimes spread a bit by sociologists is that our preferences in a romantic partner are a product of our culture, that they're very culturally specific. But in fact, the data don't back this up. A famous study surveyed people from [37] different cultures across the globe, from Americans to Zulus, on what they look for in a partner. And in every single culture across the globe, men placed more value on physical attractiveness in a partner than did women, and in every single culture, too, women placed more importance than did men on ambition and high earning power. In every culture, too, men preferred women who were younger than themselves, an average of, I think it was 2.66 years, and in every culture, too, women preferred men who were older than them, so an average of 3.42 years, which is why we've got here “Everybody needs a Sugar Daddy.” So moving on from trying to score with a partner to trying to score in basketball or football or whatever your sport is. The myth here is that sportsmen go through hot-hand streaks, Americans call them, or purple patches, we sometimes say in England, where they just can't miss, like this guy here. But in fact, what happens is that if you analyze the pattern of hits and misses statistically, it turns out that it's nearly always at random. Your brain creates patterns from the randomness. If you toss a coin, a streak of heads or tails is going to come out somewhere in the randomness, and because the brain likes to see patterns where there are none, we look at these streaks and attribute meanings to them and say, “Yeah he's really on form today,” whereas actually you would get the same pattern if you were just getting hits and misses at random. So an exception to this, however, is penalty shootouts. A recent study looking at penalty shootouts in football shows that players who represent countries with a very bad record in penalty shootouts, like, for example, England, tend to be quicker to take their shots than countries with a better record, and presumably as a result, they're more likely to miss. Which raises the question of if there's any way that we could improve people's performance. And one thing you might think about doing is punishing people for their misses and seeing if that improves them. This idea, the effect that punishment can improve performance, is what participants thought they were testing in Milgram's famous learning and punishment experiment that you've probably heard about if you're a psychology student. The story goes that participants were prepared to give what they believed to be fatal electric shocks to a fellow participant when they got a question wrong, just because someone in a white coat told them to. But this story is a myth for three reasons. Firstly and most crucially, the lab coat wasn't white, it was in fact grey. Secondly, the participants were told before the study and reminded any time they raised a concern, that although the shocks were painful, they were not fatal and indeed caused no permanent damage whatsoever. And thirdly, participants didn't give the shocks just because someone in the coat told them to. When they were interviewed after the study, all the participants said that they firmly believed that the learning and punishment study served a worthy scientific purpose which would have enduring gains for science as opposed to the momentary nonfatal discomfort caused to the participants. Okay, so I've been talking for about 12 minutes now, and you've probably been sitting there listening to me, analyzing my speech patterns and body language and trying to work out if you should take any notice of what I'm saying, whether I'm telling the truth or whether I'm lying, but if so you've probably completely failed, because although we all think we can catch a liar from their body language and speech patterns, hundreds of psychological tests over the years have shown that all of us, including police officers and detectives, are basically at chance when it comes to detecting lies from body language and verbal patterns. Interestingly, there is one exception: TV appeals for missing relatives. It's quite easy to predict when the relatives are missing and when the appealers have in fact murdered the relatives themselves. So hoax appealers are more likely to shake their heads, to look away, and to make errors in their speech, whereas genuine appealers are more likely to express hope that the person will return safely and to avoid brutal language. So, for example, they might say “taken from us” rather than “killed.” Speaking of which, it's about time I killed this talk, but before I do, I just want to give you in 30 seconds the overarching myth of psychology. So the myth is that psychology is just a collection of interesting theories, all of which say something useful and all of which have something to offer. What I hope to have shown you in the past few minutes is that this isn't true. What we need to do is assess psychological theories by seeing what predictions they make, whether that is that listening to Mozart makes you smarter, that you learn better when information is presented in your preferred learning style or whatever it is, all of these are testable empirical predictions, and the only way we can make progress is to test these predictions against the data in tightly controlled experimental studies. And it's only by doing so that we can hope to discover which of these theories are well supported, and which, like all the ones I've told you about today, are myths. Thank you.\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_transcript[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 45s, sys: 840 ms, total: 1min 46s\n",
      "Wall time: 1min 46s\n",
      "(5858, 249)\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.5, max_features=50000,\n",
    "                                 min_df=0.2, stop_words='english',\n",
    "                                 use_idf=True, tokenizer=tokenize_and_stem, ngram_range=(1,3))\n",
    "\n",
    "%time glove_tfidf_matrix = tfidf_vectorizer.fit_transform(glove_transcript) #fit the vectorizer to synopses\n",
    "\n",
    "print(glove_tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5858x249 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 441718 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_terms = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = 1 - cosine_similarity(glove_tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 10s, sys: 4 ms, total: 1min 10s\n",
      "Wall time: 1min 10s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "num_clusters = 10\n",
    "\n",
    "km = KMeans(n_clusters=num_clusters)\n",
    "\n",
    "%time km.fit(glove_tfidf_matrix)\n",
    "\n",
    "g_clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "\n",
      "Cluster 0 words: b'percent', b'country', b'change', b'money', b'social', b'community',\n",
      "\n",
      "Cluster 1 words: b'did', b'love', b'story', b\"'d\", b'feel', b'went',\n",
      "\n",
      "Cluster 2 words: b'body', b'food', b'human', b'help', b'inside', b'water',\n",
      "\n",
      "Cluster 3 words: b'women', b'man', b'young', b'children', b'change', b'talk',\n",
      "\n",
      "Cluster 4 words: b'light', b'space', b'matter', b'ca', b'ca', b'night',\n",
      "\n",
      "Cluster 5 words: b'technology', b'information', b'human', b'able', b'problem', b'example',\n",
      "\n",
      "Cluster 6 words: b'music', b'applause', b'play', b'yeah', b'hear', b'love',\n",
      "\n",
      "Cluster 7 words: b'space', b'questions', b'word', b'words', b'power', b'form',\n",
      "\n",
      "Cluster 8 words: b'school', b'kids', b'children', b'young', b'family', b'learn',\n",
      "\n",
      "Cluster 9 words: b'water', b'food', b'place', b'small', b'space', b'big',\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Top terms per cluster:\")\n",
    "print()\n",
    "#sort cluster centers by proximity to centroid\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1] \n",
    "\n",
    "for i in range(num_clusters):\n",
    "    print(\"Cluster %d words:\" % i, end='')\n",
    "    \n",
    "    for ind in order_centroids[i, :6]: #replace 6 with n words per cluster\n",
    "        print(' %s' % vocab_frame.loc[g_terms[ind].split(' ')].values.tolist()[0][0].encode('utf-8', 'ignore'), end=',')\n",
    "    print() #add whitespace\n",
    "    print() #add whitespace\n",
    "    \n",
    "    '''print(\"Cluster %d titles:\" % i, end='')\n",
    "    for title in frame.loc[i]['title'].values.tolist():\n",
    "        print(' %s,' % title, end='')\n",
    "    print() #add whitespace\n",
    "    print() #add whitespace'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
